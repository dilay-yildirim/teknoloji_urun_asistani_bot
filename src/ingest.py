# src/ingest.py
import os
from datasets import load_dataset
from dotenv import load_dotenv
from embeddings import Embedder
from vectorstore import create_or_get_collection
from tqdm.auto import tqdm

load_dotenv()

DATASET_NAME = os.getenv("HF_DATASET_NAME", "fthbrmnby/turkish_product_reviews")
SAMPLE_LIMIT = int(os.getenv("SAMPLE_LIMIT", "50000"))

def ingest():
    print(f"ðŸ“¦ Loading dataset: {DATASET_NAME}")
    ds = load_dataset(DATASET_NAME, split="train")
    print(f"Dataset rows: {len(ds)}")

    # TÃ¼rkÃ§e dataset iÃ§in sÃ¼tun seÃ§imi
    if "sentence" in ds.column_names:
        texts = ds["sentence"]
    elif "text" in ds.column_names:
        texts = ds["text"]
    elif "review" in ds.column_names:
        texts = ds["review"]
    else:
        raise ValueError("Metin sÃ¼tunu bulunamadÄ±.")

    texts = texts[:SAMPLE_LIMIT]
    embedder = Embedder()
    collection = create_or_get_collection("reviews")

    print("ðŸ”¢ Embedding'ler hesaplanÄ±yor ve veritabanÄ±na ekleniyor...")
    batch_size = 256
    for i in tqdm(range(0, len(texts), batch_size)):
        batch = texts[i:i+batch_size]
        embs = embedder.embed_texts(batch)
        ids = [f"rev_{i+j}" for j in range(len(batch))]
        metas = [{"source": DATASET_NAME}] * len(batch)
        collection.add(ids=ids, documents=batch, metadatas=metas, embeddings=embs.tolist())
    print("âœ… Ingestion tamamlandÄ±!")

if __name__ == "__main__":
    ingest()
